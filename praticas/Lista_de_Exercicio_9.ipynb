{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "NyvxHviMpShq"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGlmyFQMaR-U"
      },
      "source": [
        "# Lista de Exercício 09\n",
        "### Introdução à Visão Computacional (SEL0339/SEL5886)\n",
        "\n",
        "**Instruções:**\n",
        "\n",
        " 1. Esta lista consiste de 2 exercícios.\n",
        " 1. Deve-se colocar comentários nos códigos desenvolvidos.\n",
        " 1. As perguntas devem ser respondidas também como comentários no arquivo.\n",
        " 1. Colocar seu nome e número USP abaixo.\n",
        " 1. Quaisquer problemas na execução das listas, entrar em contato com os monitores.\n",
        " 1. Depois de terminado os exercícios, deve ser gerado um arquivo **extensão .ipynb** para ser enviado ao professor pelo E-DISCIPLINAS da disciplina até a data máxima de entrega.\n",
        " 1. Caso não seja enviado, o aluno ficará sem nota.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        " <table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/LAVI-USP/SEL0339-SEL5886_2022/blob/master/praticas/Lista_de_Exercicio_9.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Executar no Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/LAVI-USP/SEL0339-SEL5886_2022/blob/master/praticas/Lista_de_Exercicio_9.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />Ver codigo fonte no GitHub</a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3qYz1dB-tlT"
      },
      "source": [
        "`Nome: `\n",
        "\n",
        "`Número USP: `"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9uBe7nevota"
      },
      "source": [
        "### Introdução:\n",
        "\n",
        "\n",
        "Vamos importar as bibliotecas que iremos utilizar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnKV2As4aCX1"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#bibliotecas para Cluster Analysis\n",
        "from scipy.cluster import hierarchy\n",
        "from scipy.spatial.distance import pdist\n",
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyvxHviMpShq"
      },
      "source": [
        "#### **Atenção**: os códigos abaixo são para fazer o download das imagens (EXECUTE-OS). Os mesmos não fazem parte dessa prática. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Amk5CM273Afp"
      },
      "source": [
        "import urllib.request\n",
        "\n",
        "try:\n",
        "  urllib.request.urlretrieve(\"https://github.com/LAVI-USP/SEL0339-SEL5886_2022/raw/main/imagens/pratica_09/flores.csv\", \"flores.csv\")\n",
        "except:\n",
        "  print(\"[ERRO] Não foi possível fazer o download das imagens dessa prática. Entre em contato com o monitor\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvHo7Slr5Jn4"
      },
      "source": [
        "### 1) Análise de Agrupamentos (*Cluster Analysis*)\n",
        "\n",
        "Uma forma de agrupar dados que não possuem classes preestabelecidas é utilizando um método não-supervisionado, como o algoritmo de análise hierárquica e seu dendrograma equivalente. Outro método é o K-Means, que por meio de um método iterativo encontra K grupos de acordo com uma métrica de similaridade, como a distância euclidiana.\n",
        "\n",
        "Abaixo temos um conjunto de dados sobre algumas flores. Neste exercício realizaremos o agrupamento dessas flores utilizando atributos apresentados (Comprimento da sépala, Largura da sépala, Comprimento da pétala).\n",
        "\n",
        "<center><figcaption><b> Tabela 1: </b> Relação de algumas flores</b></figcaption>\n",
        "</figure>\n",
        "\n",
        ">Flor | Comprimento da sépala (mm) | Largura da sépala (mm) | Comprimento da pétala (mm)\n",
        ">--- | --- | --- | ---\n",
        "><center>Flor 1 | <center>41 | <center>40 | <center>14\n",
        "><center>Flor 2 | <center>57 | <center>3 | <center>32 \n",
        "><center>Flor 3 | <center>51 | <center>5 | <center>36\n",
        "><center>Flor 4 | <center>68 | <center>28 | <center>54\n",
        "><center>Flor 5 | <center>46 | <center>38 | <center>14\n",
        "><center>Flor 6 | <center>44 | <center>39 | <center>17 \n",
        "><center>Flor 7  | <center>64 | <center>24 | <center>52\n",
        "><center>Flor 8  | <center>61 | <center>3 | <center>36\n",
        "><center>Flor 9  | <center>55 | <center>4 | <center>34\n",
        "><center>Flor 10  | <center>46 | <center>41 | <center>15\n",
        "><center>Flor 11  | <center>56 | <center>3 | <center>31\n",
        "><center>Flor 12  | <center>69 | <center>26 | <center>51\n",
        "><center>Flor 13  | <center>66 | <center>25 | <center>55\n",
        "><center>Flor 14  | <center>45 | <center>37 | <center>14\n",
        "><center>Flor 15  | <center>69 | <center>26 | <center>51\n",
        "</center>\n",
        "\n",
        "**Exercício:**\n",
        "\n",
        "**1**. Carregar a tabela de dados disponível no arquivo **flores.csv**. Os dados seguem a mesma ordem apresentada na **Tabela 1**. \n",
        "\n",
        "**2**. Fazer a padronização dos dados pela amostra de acordo com a fórmula abaixo:\n",
        "\n",
        "\\begin{equation}\n",
        "  Z = \\frac{X - \\bar{X}}{\\sigma_{X}}\n",
        "\\end{equation}\n",
        "\n",
        "onde $X$ representa o atributo analisado, $\\bar{X}$ o seu valor médio e $\\sigma_{X}$ o sue desvio padrão.\n",
        "\n",
        "**3**. Encontrar a Matriz de Distância dos dados padronizados em (**2**) utilizando a função [**pdist**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.pdist.html#scipy.spatial.distance.pdist), que retorna a Matriz de Distância condensada (apenas os valores acima da diagonal principal), ideal para a utilização com as demais funções da biblioteca **scipy** para tal finalidade.\n",
        "\n",
        "* `D = pdist(M) %‘M’ é a matriz padronizada`\n",
        "\n",
        "**4**. Definir as Ligações para agrupar os objetos/Vetores utilizando a Ligação Centróide. [**hierarchy.linkage**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html#scipy.cluster.hierarchy.linkage)\n",
        "\n",
        "* `Z = hierarchy.linkage(D,'centroid')`\n",
        "\n",
        "**5**. Plotar o Dendrograma de Z e expliquar o significado de cada ramo. [**hierarchy.dendrogram**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.dendrogram.html)\n",
        "\n",
        "* `H = hierarchy.dendrogram(Z,labels=nomes,orientation='right')`\n",
        "\n",
        "OBS: O eixo de similaridade para o caso da função do SciPy é apresentado com valores de nível de distância em lugar de similaridade. \n",
        "\n",
        "**6**. Qual o limiar que se deve estabelecer para separar as flores em 3 grupos?\n",
        "\n",
        "**7**. Aplicar o método K-means (para k=3) para tentar agrupar os vetores de atributos. Imprimir os valores dos centróides e os agrupamentos após o método convergir. \n",
        "\n",
        "* É possível utilizar as funções (métodos) da classe [**KMeans**](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) da biblioteca **sklearn**:\n",
        "\n",
        "  `kmeans = KMeans(n_clusters=numero_de_clusters, random_state=0).fit(dados_padronizados)`\n",
        "  \n",
        "  `classe_de_cada_amostra = kmeans.labels_`\n",
        "\n",
        "  `centroides = kmeans.cluster_centers_`\n",
        "\n",
        "**8**. Utilizando a função [**scatter3D**](https://www.geeksforgeeks.org/3d-scatter-plotting-in-python-using-matplotlib/) do matplotlib, plote o espaço tridimensional com os atributos (Comprimento da sépala, Largura da sépala, Comprimento da pétala) de cada flor, além de indicar os 3 centroides calculados.\n",
        "\n",
        "**9**. Com os centroides encontrados em (**3**), verifique em qual Grupo (Cluster) a nova flor (Flor Teste) é classificada, verificando com qual tem maior similaridade (utilize a distância Euclidiana para verificação da classe) e não se esqueça de aplicar a padronização baseada no conjunto de treino.\n",
        "\n",
        "<center>\n",
        "\n",
        ">Flor | Comprimento da sépala (mm) | Largura da sépala (mm) | Comprimento da pétala (mm)\n",
        ">--- | --- | --- | ---\n",
        "><center>Flor Teste | <center>56 | <center>11 | <center>31\n",
        "</center>\n",
        "\n",
        "* É possível utilziar um método do **KMeans** para realizar a classificação do novo vetor de característica:\n",
        "\n",
        "  `nova_predição = kmeans.predict(vetor_flor_teste)`\n",
        "\n",
        "\n",
        "<font size=\"3\" color=\"darkblue\"><b>Dicas:</b></font>\n",
        "\n",
        "\n",
        "*  Você pode utilizar a função [np.genfromtxt](https://numpy.org/doc/stable/reference/generated/numpy.genfromtxt.html#numpy.genfromtxt) para carregar o arquivo .csv. Em geral, para esse tipo de arquivo é utilizada a biblioteca Pandas.\n",
        "\n",
        "*Ex:*\n",
        "``` python\n",
        "    dados_flores = np.genfromtxt('flores.csv',dtype=int,delimiter=';')\n",
        "```\n",
        "\n",
        "* Você pode utilizar a função [np.linalg.norm](https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html) da biblioteca `numpy.linalg` para calcular a distância entre os vetores.\n",
        "\n",
        "*Ex:*\n",
        "``` python\n",
        "    distancia = np.linalg.norm(diferenca_entre_vetores)\n",
        "```\n",
        "\n",
        "* O dendrograma pela função da biblioteca scipy é plotado em níveis de distância, em lugar de indicar a similaridade como apresentado em aula. Entretanto, a análise é análoga. O seu tamanho pode ser definido como uma plt.figure:\n",
        "\n",
        "*Ex:*\n",
        "``` python\n",
        "    plt.figure(figsize=(largura,altura))\n",
        "    dn = hierarchy.dendrogram(Z,labels=labels,orientation='right')\n",
        "    plt.show()\n",
        "```   \n",
        "* Para o gráfico 3D, pode-se plotá-lo utilizando funções do matplotlib, como pelo seguinte exemplo:\n",
        "\n",
        "``` python\n",
        "    fig = plt.figure(figsize = (largura, altura))\n",
        "    ax = plt.axes(projection =\"3d\")\n",
        "    # Criando o  plot\n",
        "    # As coordenadas x, y e z podem ser vetores com várias coordenadas em uma quantidade igual de valores. O parâmetro c ou color, pode ser um vetor de cores ou apenas uma cor.\n",
        "    ax.scatter3D(x, y, z, c=vetor_de_cores,s=tamanho_do_ponto)\n",
        "    # O ax.text permite adicionar uma etiqueta ao ponto que se deseja. Se preferir etiquetar todos os pontos é possível chamar a função em um laço for\n",
        "    ax.text(x, y, z,  'etiqueta', size=10, zorder=1, color='k')\n",
        "    ax.set_xlabel('Atributo 1')\n",
        "    ax.set_ylabel('Atributo 2')\n",
        "    ax.set_zlabel('Atributo 3')\n",
        "    plt.title(\"Títlo do Gráfico\")\n",
        "    plt.show()\n",
        "```  \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## -- Seu código começa AQUI -- ##\n",
        "\n",
        "## -- Seu código termina AQUI -- ##\n",
        "\n",
        "## -- Comentários -- ##"
      ],
      "metadata": {
        "id": "7vDhrSvQ62uZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Rede Neural Convolucional (CNN)\n",
        "\n",
        "Este exercício demonstra o treinamento de uma Rede Neural Convolucional (CNN) simples para classificar imagens de um banco de dados chamado [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist). Utilizaremos uma biblioteca chamada [Keras](https://www.tensorflow.org/guide/keras/overview) para criar e treinar o modelo.\n",
        "\n",
        "**Referências:** \n",
        "\n",
        "*   Tensorflow  - [CNN](https://www.tensorflow.org/tutorials/images/cnn)\n",
        "*   Tensorflow  - [Image classification](https://www.tensorflow.org/tutorials/keras/classification#build_the_model)\n",
        "\n",
        "Vamos importar as bibliotecas que iremos utilizar para a rede neural:"
      ],
      "metadata": {
        "id": "d6dQee6DWJtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models"
      ],
      "metadata": {
        "id": "FboswNdgWKmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1) DATASET\n",
        "\n",
        "O conjunto de dados (*dataset*) Fashion MNIST contém 70.000 imagens grayscale de 10 classes, conforme mostrado na Tabela 2. O conjunto de dados é dividido em 60.000 imagens de treinamento e 10.000 imagens de teste.\n",
        "\n",
        "<center><figcaption><b> Tabela 2: </b> Classes e seus respectivos rótulos.</b></figcaption>\n",
        "</figure>\n",
        "\n",
        "| Classe          | Rotulo (label) |\n",
        "|-----------------|----------------|\n",
        "| T-shirt/top     |        0       |\n",
        "| Trouser         |        1       |\n",
        "| Pullover        |        2       |\n",
        "| Dress           |        3       |\n",
        "| Coat            |        4       |\n",
        "| Sandal          |        5       |\n",
        "| Shirt           |        6       |\n",
        "| Sneaker         |        7       |\n",
        "| Bag             |        8       |\n",
        "| Ankle Boot      |        9       |\n",
        "</center>"
      ],
      "metadata": {
        "id": "KdEFaNylWMwu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercício:**\n",
        "\n",
        "* Mostre o formato, o tipo e valores máximo e mínimo das variáveis train_images e train_labels. Plote uma imagem qualquer e coloque em seu título o respectivo label.\n",
        "\n",
        "* Mostre o formato, o tipo e valores máximo e mínimo das variáveis test_images e test_labels. Plote uma imagem qualquer e coloque em seu título o respectivo label."
      ],
      "metadata": {
        "id": "gXs6NGqnWOuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz contendo os rótulos, em ordem, conforme Tabela 2\n",
        "class_names = ['t-shirt/top', 'trouser', 'pullover', 'dress', 'coat',\n",
        "               'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
        "\n",
        "# Carrega a base de dados FASHION_MNIST\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.fashion_mnist.load_data()\n",
        "\n",
        "## -- Seu código começa AQUI -- ##\n",
        "\n",
        "## -- Seu código termina AQUI -- ##"
      ],
      "metadata": {
        "id": "UQhDeyIzWQz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### *Inspeção do dataset*\n",
        "\n",
        "Vamos inspecionar as 25 primeiras imagens do conjunto de treinamento."
      ],
      "metadata": {
        "id": "8twEDOu6WTdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[train_labels[i]])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bcirkJNBWVIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2) MODELO\n",
        "\n",
        "Podemos construir um modelo utilizando blocos da biblioteca Keras importada logo no início deste notebook. A construção é sequencial, ou seja, vamos adicionando camadas (layers) ao modelo. Existem diversos tipos de camadas, com funções diversas. Vamos usar aqui as camadas de convolução, de pooling, de achatamento e densa. Repare que todas estas, exceto a camada de pooling, tem seus pesos ajustados durante o treinamento. O desafio é encontrar uma combinação de camadas (arquitetura) que torne a generalização do seu modelo eficiente.\n",
        "\n",
        "Vamos criar dois modelos diferentes de classificadores para entender o efeito da arquitetura no resultado. Queremos que a rede aprenda a diferenciar dentre as 10 classes do dataset importado anteriomente.\n",
        "\n",
        "A função a seguir constrói o modelo conforme os parâmetros de entrada, sendo:\n",
        "\n",
        "* `input_shape`: formato dos dados de entrada\n",
        "* `n_classes`: número de classes de saída\n",
        "* `n_filtros_conv`: lista 1D contendo o número de filtros a serem utilizados na camada de convolução. Note que o tamanho desta matriz vai ditar quantas camadas deste tipo devem ser adicionadas ao modelo. Fixamos o tamanho do kernel do filtro em 3.\n",
        "* `n_filtros_dense`: lista 1D contendo o número de neurônios a serem utilizados na camada densa. Note que o tamanho desta matriz vai ditar quantas camadas deste tipo devem ser adicionadas ao modelo."
      ],
      "metadata": {
        "id": "bkb9KhE6WWZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape, n_classes, n_filtros_conv, n_filtros_dense):\n",
        "  '''\n",
        "  layers.Conv2D       -> Camada de convolução\n",
        "  layers.MaxPooling2D -> Camada de \"pooling\"\n",
        "  layers.Flatten      -> Camada de achatamento\n",
        "  layers.Dense        -> Camada de neurônios\n",
        "  '''\n",
        "\n",
        "  kernel_size = 3\n",
        "\n",
        "  modelo = models.Sequential()\n",
        "\n",
        "  for idx, filtro in enumerate(n_filtros_conv):\n",
        "    if idx == 0:\n",
        "       modelo.add(layers.Conv2D(filtro, kernel_size, activation='relu', input_shape=(input_shape[0],input_shape[1],1)))\n",
        "       modelo.add(layers.MaxPooling2D((2, 2)))\n",
        "    elif idx == len(n_filtros_conv)-1:     \n",
        "       modelo.add(layers.Conv2D(filtro, kernel_size, activation='relu'))\n",
        "    else:\n",
        "       modelo.add(layers.Conv2D(filtro, kernel_size, activation='relu'))\n",
        "       modelo.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "  modelo.add(layers.Flatten())\n",
        "  \n",
        "  if len(n_filtros_dense) == 0:\n",
        "    modelo.add(layers.Dense(n_classes))\n",
        "  else:\n",
        "    for idx, filtro in enumerate(n_filtros_dense):\n",
        "      if idx == len(n_filtros_dense)-1:\n",
        "        modelo.add(layers.Dense(n_classes))\n",
        "      else:\n",
        "        modelo.add(layers.Dense(filtro, activation='relu'))\n",
        "\n",
        "  modelo.summary()\n",
        "\n",
        "  return modelo"
      ],
      "metadata": {
        "id": "XLmcS2vAWZAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercício - modelo_1:**\n",
        "\n",
        "Utilizando a função dada acima, construa o primeiro modelo e o atribua a uma variável chamada `modelo_1`. Utilize as informações do dataset importado para configurar os parâmetros da função.\n",
        "\n",
        "Neste modelo, utilizaremos apenas 1 camada de convolução com 4 filtros e 1 camada densa com 32 neurônios.\n",
        "\n",
        "Em seguida, o modelo deve ser compilado. Como loss, utilizaremos a entropia cruzada (com otimizador Adam) e a métrica a ser usada na avaliação será a acurácia."
      ],
      "metadata": {
        "id": "cFfzppLAWbyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Número de classes para classificar\n",
        "n_classes = \n",
        "# Formato da imagem que sera input da rede\n",
        "input_shape = \n",
        "\n",
        "# Número de filtros em cada camada de convolução\n",
        "n_filtros_conv = [4]\n",
        "# Número de filtros dense\n",
        "n_filtros_dense = [32]\n",
        "\n",
        "modelo_1 = \n",
        "\n",
        "# Compila o modelo com o otimizador Adam, \n",
        "# função de perda Sparse Categorical Crossentropy e \n",
        "# monitora o modelo através da acurácia\n",
        "modelo_1.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(\"Modelo 1 compilado!\")"
      ],
      "metadata": {
        "id": "PkHQ1LAyWdMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercício - modelo_2:**\n",
        "\n",
        "Agora construa o segundo modelo e o atribua a uma variável chamada `modelo_2`. Utilize as mesmas informações da dataset importado para configurar os parâmetros da função.\n",
        "\n",
        "Neste modelo, utilizaremos 3 camadas de convolução com 16, 32 e 32 filtros e 3 camadas densas com 64 neurônios cada uma. Em seguida, o modelo deve ser compilado. Como loss, utilizaremos a entropia cruzada (com otimizador Adam) e a métrica a ser usada na avaliação será a acurácia."
      ],
      "metadata": {
        "id": "kslYBBFdWfNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_filtros_conv = [32,64,64]\n",
        "n_filtros_dense = [64,64,128]\n",
        "\n",
        "modelo_2 = \n",
        "\n",
        "modelo_2.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(\"Modelo 2 compilado!\")"
      ],
      "metadata": {
        "id": "xrzZrC1GWgxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3) TREINAMENTO\n",
        "\n",
        "Vamos realizar o treinamento dos dois modelos criados durante 50 épocas. Uma época significa que todas as amostras do dataset passaram pela rede. Para avaliarmos como anda o treinamento, precisamos calcular uma métrica a cada época - validação. Para isso, vamos separar 10% do dataset de treinamento para este subset. Na função `fit` existe esta opção disponível.  \n",
        "\n",
        "`metricas = modelo.fit(images, labels, epochs, validation_split=0.1)`\n",
        "\n",
        "**Exercício:**\n",
        "\n",
        "Complete o código a seguir para prosseguir com o treinamento de ambos os modelos (separadamente), conforme orientação acima. No final de cada treinamento serão plotados os gráficos de loss e acurácia tanto do treinamento quanto da validação."
      ],
      "metadata": {
        "id": "mWZ_N_bAWicO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## --- MODELO 1 ---\n",
        "\n",
        "## -- Seu código começa AQUI -- ##\n",
        "\n",
        "n_epochs = \n",
        "\n",
        "metricas = \n",
        "\n",
        "## -- Seu código termina AQUI -- ##\n",
        "\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(metricas.history['accuracy'], label='Acurácia')\n",
        "plt.plot(metricas.history['val_accuracy'], label='Acurácia Val')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Acurácia')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(metricas.history['loss'], label='Perda')\n",
        "plt.plot(metricas.history['val_loss'], label='Perda Val')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "S3oYDMwQWklf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## --- MODELO 2 ---\n",
        "\n",
        "## -- Seu código começa AQUI -- ##\n",
        "\n",
        "n_epochs = \n",
        "\n",
        "metricas = \n",
        "\n",
        "## -- Seu código termina AQUI -- ##\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(metricas.history['accuracy'], label='Acurácia')\n",
        "plt.plot(metricas.history['val_accuracy'], label='Acurácia Val')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Acurácia')\n",
        "#plt.ylim([0.5, 1])\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(metricas.history['loss'], label='Perda')\n",
        "plt.plot(metricas.history['val_loss'], label='Perda Val')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Perda')\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "iT0bjDpdWnwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercício:**\n",
        "\n",
        "* Com base nos gráficos mostrados acima, qual modelo você escolheria para utilizar? Justifique o motivo. [Aqui](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit) você pode encontrar mais informações sobre como analisar os resultados do treinamento."
      ],
      "metadata": {
        "id": "AWVcKD2cWpcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## RESPOSTA: "
      ],
      "metadata": {
        "id": "hj2cTUbBWrdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4) TESTE\n",
        " \n",
        "Utilizando o modelo escolhido (modelo_1 ou modelo_2), verifique a acurácia do modelo a respeito do dataset de teste. Para isso, podemos usar uma função da biblioteca também já disponibilizada `model.evaluate()`. Ela retorna os valores de loss e acurácia para o dataset utilizado. Utilize todo o dataset de teste para esta avaliação.\n",
        "\n",
        "`loss, acc = model.evaluate(images, labels)`"
      ],
      "metadata": {
        "id": "TBr7CV-QWvfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## -- Seu código começa AQUI -- ##\n",
        "\n",
        "## -- Seu código termina AQUI -- ##"
      ],
      "metadata": {
        "id": "RDzRefvpWw9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com o modelo treinado, você pode usá-lo para fazer previsões sobre algumas imagens. Para isso, vamos utilizar o método `model.predict`. O modelo tem como saída, dados do tipo [logits](https://developers.google.com/machine-learning/glossary#logits). Para transformar esses dados em probabilidades, anexe uma camada [softmax](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Softmax), que são mais fáceis de interpretar."
      ],
      "metadata": {
        "id": "qlnlof5jWyWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Escolha uma imagem para a previsão { run: \"auto\" }\n",
        "\n",
        "# Configure aqui o modelo escolhido (modelo_1 ou modelo_2)\n",
        "modelo = \n",
        "\n",
        "imgIndex = 5304 #@param {type:\"slider\", min:0, max:9999, step:1}\n",
        "\n",
        "imgInput = test_images[imgIndex:imgIndex+1,:]\n",
        "\n",
        "# Anexa uma camada softmax\n",
        "modelo_probabilidade = tf.keras.Sequential([modelo, tf.keras.layers.Softmax()])\n",
        "\n",
        "# Faz a previsao\n",
        "probs = modelo_probabilidade.predict(imgInput)\n",
        "\n",
        "# Encontra qual o índice com a maior probabilidade\n",
        "classe_pred = np.argmax(probs)\n",
        "\n",
        "# Mostra a figura\n",
        "plt.figure(figsize=(2,2))\n",
        "plt.imshow(imgInput[0,:], cmap=plt.cm.binary)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.grid(False)\n",
        "string = class_names[classe_pred] + \" {:.2f}%\".format(probs[0,classe_pred] *100)\n",
        "\n",
        "\n",
        "# A imagem foi classificada corretamente? \n",
        "if class_names[test_labels[imgIndex]] == class_names[classe_pred]:\n",
        "  # Se sim, mostre a legenda como verde\n",
        "  plt.xlabel(string ,color='green')\n",
        "else:\n",
        "  # Se nao, mostre a legenda como vermelha\n",
        "  plt.xlabel(string,color='red')\n",
        "  print(\"O correto seria: \", class_names[test_labels[imgIndex]])\n"
      ],
      "metadata": {
        "id": "xBjvBlACW1C7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}